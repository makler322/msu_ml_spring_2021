{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Gradient_Boosting.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQG2-8OKZar-"
      },
      "source": [
        "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
        "## Домашнее задание №4 - Градиентный бустинг\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e37rap4VZasE"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 10 мая 2021, 08:30   \n",
        "**Штраф за опоздание:** -2 балла после 08:30 10 мая, -4 балла после 08:30 17 мая, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
        "\n",
        "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
        "[ML0221, Задание 4] Фамилия Имя. \n",
        "\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSoz1QskZasF"
      },
      "source": [
        "##  Считаем производные для функций потерь (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQaAaXcZasG"
      },
      "source": [
        "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
        "\n",
        "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
        "\n",
        "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
        "\n",
        "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eorBZNNBZasH"
      },
      "source": [
        "### Таргеты\n",
        "\n",
        "1.   MSE : $-\\frac{dL}{da(x_i)}(L(a(x_i), y_i)) = 2 (y_i - a(x_i))$\n",
        "2.   Экспоненциальная : $-\\frac{dL}{da(x_i)}(L(a(x_i), y_i)) = exp(-a(x_i)y_i)y_i$\n",
        "3.   Логистическая : $-\\frac{dL}{da(x_i)}(L(a(x_i), y_i)) = \\frac{y_i}{exp(a(x_i)y_i) + 1}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUwHfElWZasH"
      },
      "source": [
        "##  Реализуем градиентный бустинг (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnOgwCZnZasH"
      },
      "source": [
        "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6vVnwDOZasH"
      },
      "source": [
        "Детали реализации:\n",
        "\n",
        "-- должно поддерживаться 3 функции потерь\n",
        "\n",
        "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
        "\n",
        "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
        "\n",
        "-- шаг в бустинге можно не подбирать, можно брать константный\n",
        "\n",
        "-- можно брать разные модели в качестве инициализации бустинга\n",
        "\n",
        "-- должны поддерживаться следующие параметры:\n",
        "\n",
        "а) число итераций\n",
        "б) размер шага\n",
        "в) процент случайных фичей при построении одного дерева\n",
        "д) процент случайных объектов при построении одного дерева\n",
        "е) параметры базового алгоритма (передавайте через **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hif6fKOPZasI"
      },
      "source": [
        "import numpy as np\n",
        "from math import exp\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "JlrneaLoZasJ"
      },
      "source": [
        "class MyGradientBoostingClassifier:\n",
        "\n",
        "    def __init__(self, loss='mse', learning_rate=0.1, n_estimators=100, colsample=1, subsample=1, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        loss -- один из 3 лоссов:\n",
        "        learning_rate -- шаг бустинга\n",
        "        n_estimators -- число итераций\n",
        "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
        "        subsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
        "        args, kwargs -- параметры  базовых моделей\n",
        "        \"\"\"\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.colsample = colsample\n",
        "        self.subsample = subsample\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "    \n",
        "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
        "        \"\"\"\n",
        "        X -- объекты для обучения:\n",
        "        y -- таргеты для обучения\n",
        "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
        "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
        "        \"\"\"\n",
        "\n",
        "        # 1 шаг: инициализировать f_0\n",
        "        # 2 шаг: обучить f_k на выборке (x_i, -dL/dF) на MSE функции потерь. Посчитать антиградиент.\n",
        "        # 3 шаг: найти шаг c_k. В нашем случае это self.learning_rate\n",
        "        # 4 шаг: достроить ансамбль F_k = F_k-1 + c_k*f_k\n",
        "        # 5 шаг: повторять 2-4 M итераций\n",
        "\n",
        "        # для 4 шага\n",
        "        self.models = []\n",
        "        #---1---\n",
        "        if init_model == None:\n",
        "            model = None\n",
        "        else:\n",
        "            model = init_model.fit(X, y)\n",
        "        \n",
        "        self.models.append(model)\n",
        "        #---2--- \n",
        "        for i in range(self.n_estimators - 1):  # 1 модель считаем вручную\n",
        "            model = base_model(*self.args, **self.kwargs)\n",
        "            if self.loss == 'mse':\n",
        "                model.fit(X, 2*(y - self.predict(X)))\n",
        "            elif self.loss == 'exp':\n",
        "                model.fit(X, exp(-self.predict(X)@y)*y)\n",
        "            elif self.loss == 'log':\n",
        "                model.fit(X, y/(exp(self.predict(X)*y)+1))\n",
        "            self.models.append(model)  # 4 шаг\n",
        "            \n",
        "\n",
        "        \n",
        "    def predict(self, X):\n",
        "        answer = np.zeros(len(X))\n",
        "        first_flag = True\n",
        "        for i in self.models:\n",
        "            if first_flag:\n",
        "                if i != None:\n",
        "                    answer += i.predict(X)\n",
        "                first_flag = False\n",
        "            else:\n",
        "                answer += self.learning_rate * i.predict(X) \n",
        "        return np.rint(answer).astype(int)\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNqfQBblZasK"
      },
      "source": [
        "my_clf = MyGradientBoostingClassifier()\n",
        "clf = GradientBoostingClassifier()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "P6MC62v3ZasM"
      },
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0GliMXIZasM",
        "outputId": "680e77b1-5a1f-4bce-a74f-a0048e8dfe0d"
      },
      "source": [
        "my_clf.fit(X_train, y_train)\n",
        "clf.fit(X_train, y_train)\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9444444444444444\n",
            "0.9444444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLzu4VWBZasN"
      },
      "source": [
        "## Подбираем параметры (2 балла)\n",
        "\n",
        "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpq5XNpHZasN"
      },
      "source": [
        "В задании нужно\n",
        "\n",
        "1) Построить график точности в зависимости от числа итераций на валидации.\n",
        "\n",
        "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmAwdX-GZasN"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "X, y = fetch_california_housing(return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyMGiYtjZasN",
        "outputId": "4298415a-7b38-4378-99dc-4a211c16a249"
      },
      "source": [
        "# Превращаем регрессию в классификацию\n",
        "y = (y > 2.0).astype(int)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20640, 8) (20640,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "SZ0ZDycDZasP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UZe1RkUzZasP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYAKXEhmZasP"
      },
      "source": [
        "## BooBag BagBoo (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxHrnuw0ZasP"
      },
      "source": [
        "Попробуем объединить бустинг и бэгинг. Давайте\n",
        "\n",
        "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
        "\n",
        "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuhQCpRpZasP"
      },
      "source": [
        "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ngMI7fQ1ZasP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "HjrA3btNZasP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ke9jWrAZasQ"
      },
      "source": [
        "## Умная инициализация (1 балл)\n",
        "\n",
        "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
        "\n",
        "Получилось ли улучшить качество? Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "T4Sx0UpQZasQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "V0GB9CmOZasQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZaHYphzZasQ"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAIkL3WhZasR"
      },
      "source": [
        "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFVCKX7ZasS"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwJpxsPPZasS"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pWzaIUcZasS"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "zdM3Yuf8ZasS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "eeL4MzbVZasT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}